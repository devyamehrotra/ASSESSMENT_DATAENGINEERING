# ASSESSMENT_DATAENGINEERING

This document is designed to be read in parallel with the code in the ASSESSMENT_DATAENGINEERING repository. 


 PROJECT STRUCTURE

```bash

â”œâ”€â”€ .idea
â”‚   â”œâ”€â”€ .gitignore
â”‚   â”œâ”€â”€ inspectionProfiles
â”‚   â”‚   â”œâ”€â”€ Project_Default.xml
â”‚   â”‚   â””â”€â”€ profiles_settings.xml
â”‚   â”œâ”€â”€ misc.xml
â”‚   â”œâ”€â”€ modules.xml
â”‚   â”œâ”€â”€ ASSESSMENT_DATAENGINEERING.iml
â”‚   â””â”€â”€ workspace.xml
â”œâ”€â”€ .pycache__
â”‚   â”œâ”€â”€ create_spark.cpython-310.pyc
â”‚   â”œâ”€â”€ driver.cpython-310.pyc
â”‚   â”œâ”€â”€ extraction.cpython-310.pyc
â”‚   â”œâ”€â”€ get_env_variables.cpython-310.pyc
â”‚   â”œâ”€â”€ ingest.cpython-310.pyc
â”‚   â”œâ”€â”€ udf.cpython-310.pyc
â”‚   â””â”€â”€ validate.cpython-310.pyc
â”œâ”€â”€ Properties
â”‚   â”œâ”€â”€ Configuration
â”‚   â”‚   â””â”€â”€ logging.config
â”œâ”€â”€ source
â”‚   â””â”€â”€ oltp
â”‚       â””â”€â”€ database.csv
â”œâ”€â”€ output
â”‚   â”œâ”€â”€ csv_output
â”‚   â”‚   â”œâ”€â”€ .part-00000-3bd95e79-44ea-48c0-b397-3c954de5b9e9-c000.csv.crc
â”‚   â”‚   â”œâ”€â”€ ._SUCCESS.crc
â”‚   â”‚   â”œâ”€â”€ part-00000-3bd95e79-44ea-48c0-b397-3c954de5b9e9-c000.csv
â”‚   â”‚   â””â”€â”€ _SUCCESS
â”‚   â”œâ”€â”€ earthquake_map.html
â”‚   â””â”€â”€ parquet_output
â”‚       â”œâ”€â”€ .part-00000-4a715298-3da8-489b-bf15-aac7e9aac559-c000.snappy.parquet.crc
â”‚       â”œâ”€â”€ ._SUCCESS.crc
â”‚       â”œâ”€â”€ part-00000-4a715298-3da8-489b-bf15-aac7e9aac559-c000.snappy.parquet
â”‚       â””â”€â”€ _SUCCESS
â”œâ”€â”€ README.md
â”œâ”€â”€ application.log
â”œâ”€â”€ create_spark.py
â”œâ”€â”€ driver.py
â”œâ”€â”€ earthquake_map_adjusted.html
â”œâ”€â”€ extraction.py
â”œâ”€â”€ get_env_variables.py
â”œâ”€â”€ ingest.py
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ udf.py
â””â”€â”€ validate.py
```



## Deployment

To deploy this project run driver.py after activating venv

```bash
  python driver.py
```

PLEASE ENSURE SPARK AND HADOOP ARE INSTALLED IN YOUR SYSTEM








## ðŸš€ About Me
I'm a DATA ENGINEER AT FORWOOD SAFETY..
